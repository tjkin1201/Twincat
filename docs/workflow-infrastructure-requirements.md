# 개선된 워크플로우 구축을 위한 인프라 요구사항

## 📋 목차
0. [기존 워크플로우 상세 분석](#기존-워크플로우-상세-분석)
1. [필수 인프라](#필수-인프라)
2. [소프트웨어 스택](#소프트웨어-스택)
3. [팀 구성 및 역량](#팀-구성-및-역량)
4. [예산 및 시간](#예산-및-시간)
5. [단계별 구축 계획](#단계별-구축-계획)
6. [현실적 제약사항](#현실적-제약사항)

---

## 기존 워크플로우 상세 분석

### 0.1 전체 구조 개요

```
시작점: 요청 접수
주요 게이트웨이: SCR → WISE → LEADER APPROVE → SW DEVELOP
핵심 프로세스: MERGED → 설비 검증 → SQA TEST → TEST PASS → SCR 완료 → 활성계
예외 경로: 기각, SCR 비적용, SW RESOLVED, TEST 결과 검토
```

### 0.2 단계별 상세 분석

#### Stage 1: 요청 및 승인 단계

**1.1 SCR (Software Change Request)**
```yaml
목적: 변경 요청 정식 접수 및 문서화
입력: 요청자의 변경 요구사항
프로세스:
  - 변경 내용 기술
  - 변경 사유 명시
  - 영향도 평가 (초기)
  - 우선순위 설정
출력: SCR 문서 (고유 번호 부여)
담당: 요청자 또는 PL (Project Leader)
예상 소요시간: 0.5~1일
도구: 사내 SCR 시스템 (추정: Jira, SharePoint 등)

문제점:
  ⚠️ 모든 변경이 SCR 필수 → 작은 버그픽스도 무거운 프로세스
  ⚠️ 작성 품질 편차 큼 (템플릿 부재 시)
  ⚠️ 우선순위 기준 불명확
```

**1.2 WISE (검토/승인 시스템)**
```yaml
목적: 기술적 타당성 및 필요성 검토
입력: SCR 문서
프로세스:
  - 기술 팀 검토 (아키텍처, 보안, 품질)
  - 비용-효과 분석
  - 리소스 가용성 확인
  - 위험도 평가
출력: 승인 또는 기각
담당: 기술 위원회 또는 시니어 엔지니어
예상 소요시간: 1~3일
회의: 주 1~2회 정기 회의

기각 경로:
  → "기각" 상태로 종료
  → 사유 기록 및 요청자 피드백
  → 재신청 가능

문제점:
  ⚠️ 회의 일정 대기 시간 (병목)
  ⚠️ 승인 기준 불명확 (주관적 판단)
  ⚠️ 피드백 루프 부재 (재신청 프로세스 불명확)
```

**1.3 LEADER APPROVE (리더 최종 승인)**
```yaml
목적: 경영진/리더 레벨 최종 의사결정
입력: WISE 승인된 SCR
프로세스:
  - 비즈니스 영향도 검토
  - 우선순위 조정
  - 리소스 할당 결정
  - 일정 승인
출력: 개발 착수 승인
담당: 부서장, CTO, 또는 프로젝트 리더
예상 소요시간: 0.5~2일

문제점:
  ⚠️ 3단계 승인 (SCR → WISE → LEADER) 과도
  ⚠️ 리더 부재 시 지연
  ⚠️ 긴급 상황 대응 경로 없음
```

#### Stage 2: 개발 단계

**2.1 SW DEVELOP (소프트웨어 개발)**
```yaml
목적: 실제 코드 작성 및 구현
입력: 승인된 SCR, 요구사항 명세
프로세스:
  - 설계 (아키텍처, 상세 설계)
  - 코딩 (IEC 61131-3 PLC 코드)
  - 단위 테스트 (개발자 자체)
  - 코드 리뷰 (동료 검토)
출력: 개발 완료된 코드
담당: PLC 개발자
예상 소요시간: 3일~4주 (복잡도 의존)
도구: TwinCAT XAE, Visual Studio, Git (추정)

병렬 경로 - "SCR 비적용":
  → 긴급 수정 또는 매우 작은 변경
  → SCR 없이 직접 개발 착수
  → 리스크: 추적성 부족, 충돌 가능성

문제점:
  ⚠️ 개발 중 요구사항 변경 대응 불명확
  ⚠️ 단위 테스트 자동화 부재 (추정)
  ⚠️ 코드 리뷰 프로세스 불명확
```

**2.2 MERGED (코드 병합)**
```yaml
목적: 개발 브랜치를 메인 브랜치에 통합
입력: 개발 완료 코드, 테스트 결과
프로세스:
  - 브랜치 병합 (Git merge/rebase)
  - 충돌 해결
  - 통합 빌드 확인
  - 버전 태깅
출력: 통합된 코드베이스
담당: 개발자 + 형상관리 담당자
예상 소요시간: 0.5~1일
도구: Git, TwinCAT 프로젝트 관리

문제점:
  ⚠️ 병합 전 자동 검증 부재
  ⚠️ 충돌 발생 시 롤백 전략 불명확
  ⚠️ 빌드 실패 시 대응 프로세스 없음
```

#### Stage 3: 검증 단계

**3.1 설비 검증**
```yaml
목적: 실제 설비에서 동작 확인
입력: MERGED 코드, 테스트 시나리오
프로세스:
  - 테스트 설비 준비
  - 코드 배포 (설비 PLC)
  - 수동 테스트 실행
  - 동작 확인 (센서, 액추에이터)
  - 이상 현상 기록
출력: 설비 검증 리포트
담당: 설비 엔지니어 + 테스트 엔지니어
예상 소요시간: 1~3일
환경: 실제 설비 또는 테스트 벤치

특이사항:
  - 설비 가용 시간 제한 (생산 중단 불가)
  - 야간/주말 테스트 빈번
  - 안전 절차 필수

문제점:
  ⚠️ 설비 접근성 제한 (병목)
  ⚠️ 수동 테스트 → 재현성 낮음
  ⚠️ 테스트 커버리지 불명확
  ⚠️ 설비 검증과 SQA TEST 순차 진행 (시간 소요)
```

**3.2 설비 검증 (피드백 루프)**
```yaml
검증 실패 시:
  → "설비 검증" 박스로 돌아감 (다이어그램 루프)
  → 수정 사항 반영
  → 재검증

반복 가능:
  - 최대 반복 횟수 제한 없음 (추정)
  - 각 반복마다 1~3일 소요
  - 누적 지연 위험 높음
```

**3.3 SQA TEST (Software Quality Assurance Test)**
```yaml
목적: 품질 보증 팀의 독립적 검증
입력: 설비 검증 통과 코드
프로세스:
  - 테스트 케이스 실행 (기능, 회귀)
  - 성능 테스트 (사이클 타임, 응답성)
  - 경계값 테스트
  - 스트레스 테스트
  - 문서화 검증 (매뉴얼, 주석)
출력: SQA 테스트 리포트
담당: QA 팀
예상 소요시간: 2~5일
도구: TwinCAT Scope, 자체 테스트 도구

병렬 경로 - "SW RESOLVED" 및 "SW RESOLVED 승인":
  → 문제 발견 후 신속 수정 경로
  → 개발자가 즉시 수정
  → 간소화된 재승인 프로세스
  → 목적: 사소한 이슈 빠른 해결

문제점:
  ⚠️ SQA와 설비 검증 순차 진행 (병렬 불가 이유 불명)
  ⚠️ 테스트 자동화 부재 (추정)
  ⚠️ SW RESOLVED 경로 남용 가능성
  ⚠️ 승인 기준 불명확
```

**3.4 TEST 결과 검토**
```yaml
목적: 테스트 실패 시 원인 분석 및 대응 결정
입력: 테스트 실패 리포트
프로세스:
  - 실패 원인 분류 (코드, 요구사항, 환경)
  - 심각도 평가 (Critical, Major, Minor)
  - 대응 방안 결정
    a) 코드 수정 → SW DEVELOP 복귀
    b) 요구사항 변경 → SCR 재검토
    c) 환경 이슈 → 설비 검증 재실행
출력: 대응 계획
담당: QA 리더 + 개발 리더
예상 소요시간: 0.5~1일

피드백 루프:
  → "TEST 결과 검토" → (어디로?) 다이어그램에 불명확
  → 추정: SW DEVELOP 또는 설비 검증으로 복귀

문제점:
  ⚠️ 피드백 대상이 불명확 (다이어그램 미표시)
  ⚠️ 반복 횟수 제한 없음 → 무한 루프 가능
  ⚠️ 근본 원인 분석 (RCA) 프로세스 부재
```

**3.5 TEST PASS**
```yaml
목적: 모든 테스트 통과 확인
입력: 설비 검증 + SQA TEST 통과
조건:
  ✓ 설비 검증 통과
  ✓ SQA TEST 통과
  ✓ 문서화 완료
  ✓ 승인 요건 충족
출력: 배포 가능 상태
담당: QA 리더 승인
예상 소요시간: 0.5일 (최종 확인)

문제점:
  ⚠️ 통과 기준 불명확 (정량적 지표 부재)
  ⚠️ 회귀 테스트 범위 불명확
  ⚠️ 성능 벤치마크 없음
```

#### Stage 4: 배포 및 완료 단계

**4.1 SCR 완료**
```yaml
목적: SCR 공식 종료 및 문서화
입력: TEST PASS 승인
프로세스:
  - 최종 문서 업데이트
  - 변경 이력 기록
  - 배포 준비 (패키징)
  - 롤백 계획 수립
  - 이해관계자 통보
출력: SCR 완료 보고서
담당: PM 또는 PL
예상 소요시간: 0.5~1일

문제점:
  ⚠️ 배포 계획 불명확
  ⚠️ 롤백 전략 부재
  ⚠️ 활성계 배포 전 검증 없음
```

**4.2 활성계 (프로덕션 배포)**
```yaml
목적: 실제 운영 환경에 코드 배포
입력: SCR 완료된 코드
프로세스:
  - 다운타임 스케줄링 (생산 중단)
  - 백업 (기존 코드)
  - 배포 실행
  - 동작 확인 (초기 모니터링)
  - 생산 재개
출력: 운영 중인 새 버전
담당: 운영팀 + 개발자 (온콜)
예상 소요시간: 1~4시간 (다운타임)
시점: 야간 또는 주말

문제점:
  ⚠️ 카나리/블루-그린 배포 없음 → 위험 높음
  ⚠️ 롤백 시간 오래 걸림 (수동)
  ⚠️ 배포 후 모니터링 계획 불명확
  ⚠️ 문제 발생 시 대응 절차 불명확 (활성계 이후 경로 없음)
```

### 0.3 예외 및 특수 경로 분석

#### 경로 1: 기각 (WISE 단계)
```yaml
트리거: WISE 검토 결과 부적합
프로세스:
  - 기각 사유 기록
  - 요청자 통보
  - SCR 종료 (Closed - Rejected)
재신청:
  - 가능 (새로운 SCR 생성)
  - 사유 보완 필요

통계 (추정):
  - 기각률: 10~20%
  - 주요 사유: 우선순위 낮음, 리소스 부족, 기술적 불가능
```

#### 경로 2: SCR 비적용
```yaml
트리거: 긴급 수정 또는 매우 작은 변경
목적: SCR 프로세스 우회하여 신속 대응
프로세스:
  - 리더 구두 승인
  - 직접 개발 착수
  - 사후 SCR 작성 (선택적)
리스크:
  ⚠️ 추적성 부족
  ⚠️ 변경 이력 누락
  ⚠️ 남용 가능성
  ⚠️ 충돌 및 회귀 버그 위험

권장:
  → Fast Track 프로세스로 대체 (공식화)
```

#### 경로 3: SW RESOLVED 및 SW RESOLVED 승인
```yaml
트리거: 테스트 중 발견된 사소한 이슈
목적: 간소화된 수정 프로세스
프로세스:
  - 이슈 확인 (QA)
  - 신속 수정 (개발자)
  - 리뷰 및 승인 (간소화)
  - 재검증 (부분 테스트)
범위:
  - Minor 버그만 해당 (추정)
  - Critical 이슈는 SW DEVELOP 복귀

문제점:
  ⚠️ Minor vs Critical 기준 불명확
  ⚠️ 승인 권한 불명확
  ⚠️ 재검증 범위 불명확
```

#### 경로 4: TEST 결과 검토 (피드백 루프)
```yaml
트리거: 테스트 실패
프로세스:
  - 실패 원인 분석
  - 대응 방안 결정
  - 해당 단계로 복귀
복귀 대상 (추정):
  - SW DEVELOP: 코드 수정 필요
  - 설비 검증: 환경 이슈
  - MERGED: 충돌 또는 통합 이슈

문제점:
  ⚠️ 다이어그램에 복귀 경로 명시 안 됨
  ⚠️ 반복 제한 없음
  ⚠️ 근본 원인 분석 부재
```

### 0.4 시간 분석 (리드 타임)

#### 정상 경로 (Best Case)
```yaml
SCR 작성:              0.5일
WISE 검토:             1일
LEADER APPROVE:        0.5일
SW DEVELOP:            5일
MERGED:                0.5일
설비 검증:             2일
SQA TEST:              3일
TEST PASS:             0.5일
SCR 완료:              0.5일
활성계 배포:           0.5일
━━━━━━━━━━━━━━━━━━━━━━━━━
총 리드 타임:          14일 (약 3주)
```

#### 평균 경로 (Average Case)
```yaml
SCR 작성:              1일 (검토 및 수정)
WISE 검토:             2일 (회의 대기)
LEADER APPROVE:        1일 (부재 또는 우선순위 조정)
SW DEVELOP:            10일 (복잡도, 요구사항 변경)
MERGED:                1일 (충돌 해결)
설비 검증:             3일 (설비 접근 대기 + 1회 재검증)
SQA TEST:              5일 (이슈 발견 + SW RESOLVED)
TEST PASS:             0.5일
SCR 완료:              1일
활성계 배포:           1일 (스케줄 대기)
━━━━━━━━━━━━━━━━━━━━━━━━━
총 리드 타임:          25.5일 (약 5주)
```

#### 최악 경로 (Worst Case)
```yaml
SCR 작성:              2일
WISE 검토:             5일 (기각 → 재신청)
LEADER APPROVE:        3일
SW DEVELOP:            20일 (복잡 + 요구사항 변경 2회)
MERGED:                2일 (충돌 다수)
설비 검증:             6일 (3회 반복)
SQA TEST:              10일 (Critical 이슈 → SW DEVELOP 복귀)
  → SW DEVELOP (2차):  5일
  → 설비 검증 (2차):   2일
  → SQA TEST (2차):    4일
TEST PASS:             1일
SCR 완료:              1일
활성계 배포:           2일
━━━━━━━━━━━━━━━━━━━━━━━━━
총 리드 타임:          63일 (약 13주, 3개월)
```

### 0.5 병목 지점 (Bottleneck) 분석

#### 병목 1: WISE 검토 (상위 영향도)
```yaml
원인:
  - 주 1~2회 정기 회의 → 대기 시간
  - 검토 위원 다수 → 일정 조율 어려움
  - 승인 기준 불명확 → 재논의 빈번
영향:
  - 평균 2일 소요 (대기 1일 + 검토 1일)
  - 최악 5일 (기각 → 재신청 → 재검토)
개선 방안:
  ✓ 비동기 검토 (온라인 투표)
  ✓ 명확한 체크리스트 기준
  ✓ Fast Track 경로 (긴급 승인)
```

#### 병목 2: 설비 검증 (최상위 영향도)
```yaml
원인:
  - 설비 접근 제한 (생산 우선)
  - 야간/주말 작업 → 인력 제약
  - 수동 테스트 → 긴 시간
  - 재검증 반복 (평균 1.5회)
영향:
  - 평균 3일 소요
  - 최악 6일 (3회 반복)
  - 전체 리드 타임의 20~25% 차지
개선 방안:
  ✓ 시뮬레이션 환경 구축
  ✓ 테스트 자동화
  ✓ 전용 테스트 설비
  ✓ 병렬 검증 (SQA와 동시)
```

#### 병목 3: 순차 검증 (설비 → SQA)
```yaml
원인:
  - 설비 검증 후 SQA TEST (순차)
  - 독립적 검증 가능함에도 순차 진행
영향:
  - 검증 시간: 5~8일 (순차)
  - 병렬 시: 3~4일 (40% 단축 가능)
개선 방안:
  ✓ 병렬 검증 프로세스
  ✓ 통합 검증 게이트
```

#### 병목 4: TEST 결과 검토 피드백 루프
```yaml
원인:
  - 실패 시 원점 복귀 (SW DEVELOP)
  - 재검증 전체 반복 (설비 + SQA)
  - 근본 원인 분석 부재 → 재발 가능
영향:
  - 1회 반복: +10~15일
  - 평균 0.5회 반복 → +5~7일
  - 최악 2회 반복 → +20~30일
개선 방안:
  ✓ 근본 원인 분석 (RCA)
  ✓ 심각도 기반 부분 재검증
  ✓ 자동 회귀 테스트
  ✓ 명확한 반복 제한 (3회 Max)
```

### 0.6 리스크 분석

#### 리스크 1: 프로세스 우회 (SCR 비적용)
```yaml
확률: 중 (월 5~10건 추정)
영향: 중~높음
시나리오:
  - 긴급 수정이라는 명목으로 SCR 우회
  - 변경 이력 누락
  - 다른 작업과 충돌
  - 프로덕션 버그 발생
완화 방안:
  ✓ Fast Track 공식 프로세스
  ✓ 사후 SCR 작성 의무화
  ✓ 정기 감사 (월 1회)
```

#### 리스크 2: 테스트 불충분
```yaml
확률: 중 (프로젝트당 30%)
영향: 높음
시나리오:
  - 일정 압박으로 테스트 축소
  - 테스트 커버리지 낮음
  - 프로덕션 배포 후 버그 발견
  - 긴급 롤백 또는 핫픽스
완화 방안:
  ✓ 최소 테스트 기준 강제
  ✓ 자동화로 테스트 시간 단축
  ✓ 단계적 배포 (카나리)
```

#### 리스크 3: 롤백 실패
```yaml
확률: 저 (연 1~2회)
영향: 치명적
시나리오:
  - 프로덕션 배포 후 Critical 버그
  - 롤백 시도 → 실패 (백업 없음 또는 손상)
  - 생산 중단 (수시간~수일)
  - 재정적 손실 및 신뢰 하락
완화 방안:
  ✓ 자동 백업 (배포 전)
  ✓ 롤백 테스트 (분기 1회)
  ✓ 블루-그린 배포
  ✓ 긴급 대응 팀 (온콜)
```

#### 리스크 4: 문서 불일치
```yaml
확률: 높음 (프로젝트당 50%)
영향: 중
시나리오:
  - 코드 변경 후 문서 미업데이트
  - 운영 매뉴얼 구버전
  - 유지보수 어려움
  - 신규 인력 온보딩 지연
완화 방안:
  ✓ 문서 검증 자동화 (TEST PASS 조건)
  ✓ 코드 주석 강제
  ✓ 자동 문서 생성 (Doxygen 등)
```

### 0.7 메트릭 및 측정 지표

#### 현재 수집 가능한 메트릭 (추정)
```yaml
프로세스 메트릭:
  ✓ SCR 생성 수 (월별)
  ✓ WISE 승인율 / 기각률
  ✓ 평균 리드 타임 (SCR → 활성계)
  ✓ 단계별 소요 시간
  ✓ 재작업 횟수 (TEST 결과 검토 반복)

품질 메트릭:
  ✓ 테스트 발견 버그 수
  ✓ 프로덕션 버그 수 (배포 후 30일)
  ✓ 긴급 핫픽스 빈도
  ✓ SCR 비적용 건수

운영 메트릭:
  ✓ 배포 빈도
  ✓ 배포 성공률
  ✓ 롤백 빈도
  ✓ 평균 다운타임
```

#### 부재하는 메트릭 (개선 필요)
```yaml
자동화 메트릭:
  ✗ 빌드 성공률 / 실패율
  ✗ 자동 테스트 커버리지
  ✗ 코드 복잡도 (Cyclomatic Complexity)
  ✗ 정적 분석 결과

성능 메트릭:
  ✗ 사이클 타임 벤치마크
  ✗ 응답 시간 (PLC 응답성)
  ✗ 리소스 사용률 (CPU, 메모리)

DevOps 메트릭:
  ✗ Deployment Frequency
  ✗ Lead Time for Changes
  ✗ Change Failure Rate
  ✗ Mean Time to Restore (MTTR)
```

### 0.8 조직 및 역할 분석

#### 추정 역할 매핑
```yaml
요청자:
  - 생산 엔지니어, 품질 엔지니어, 유지보수 팀
  - 역할: 변경 요청, 요구사항 정의

SCR 관리자:
  - PM (Project Manager) 또는 PL
  - 역할: SCR 작성 지원, 추적

WISE 위원회:
  - 시니어 PLC 개발자, 아키텍트, 보안 담당자
  - 역할: 기술 검토, 타당성 평가

리더 (LEADER APPROVE):
  - 부서장, CTO, 프로젝트 리더
  - 역할: 최종 승인, 리소스 할당

PLC 개발자:
  - TwinCAT 개발자 (2~5명 추정)
  - 역할: 코딩, 단위 테스트, 코드 리뷰

형상관리 담당자:
  - DevOps 또는 시니어 개발자 (겸직)
  - 역할: Git 관리, 브랜치 전략, MERGED

설비 엔지니어:
  - 기계/전기 엔지니어 + PLC 전문가
  - 역할: 설비 검증, 하드웨어 통합

QA 팀:
  - 테스트 엔지니어 (1~3명)
  - 역할: SQA TEST, 테스트 케이스 작성

운영팀:
  - 생산 지원, 유지보수
  - 역할: 활성계 배포, 모니터링
```

#### 조직 문제점
```yaml
⚠️ 역할 중복 및 불명확:
  - 형상관리 담당자 전담 없음 (추정)
  - DevOps 역할 부재
  - 자동화 전문가 없음

⚠️ 의사소통 오버헤드:
  - 다수 승인 단계 (3단계)
  - 부서 간 조율 시간 소요

⚠️ 스킬 격차:
  - DevOps/CI-CD 경험 부족
  - 테스트 자동화 역량 부족
  - Git 고급 기능 미활용
```

### 0.9 도구 및 시스템 분석

#### 현재 사용 도구 (추정)
```yaml
개발:
  - TwinCAT 3 XAE (확실)
  - Visual Studio (TwinCAT 통합)
  - Git (버전 관리, 추정)

프로세스 관리:
  - SCR 시스템 (Jira, SharePoint, 자체 시스템?)
  - 이메일 / 메신저 (승인 알림)

테스트:
  - TwinCAT Scope View (로직 분석)
  - 수동 테스트 (주로)

배포:
  - 수동 복사 또는 스크립트
  - TwinCAT Remote Manager (?)

모니터링:
  - TwinCAT EventLogger
  - 수동 로그 확인
```

#### 부재하는 도구 (개선 필요)
```yaml
CI/CD:
  ✗ Jenkins, Azure Pipelines, GitLab CI
  ✗ 자동 빌드 파이프라인
  ✗ 자동 배포 도구

테스트:
  ✗ TcUnit (단위 테스트 프레임워크)
  ✗ 자동화 테스트 도구
  ✗ 테스트 커버리지 측정

품질:
  ✗ SonarQube (정적 분석)
  ✗ 코드 리뷰 도구 (Gerrit, GitHub PR)

모니터링:
  ✗ Prometheus, Grafana
  ✗ 실시간 대시보드
  ✗ 알림 시스템 (Slack, PagerDuty)
```

### 0.10 개선 우선순위 (기존 워크플로우 기준)

#### 즉시 개선 (Quick Wins) - 1개월
```yaml
1. Fast Track 프로세스 추가
   - SCR 비적용 공식화
   - 긴급 승인 경로
   - 예상 효과: 긴급 대응 70% 단축

2. WISE 승인 기준 문서화
   - 체크리스트 작성
   - 비동기 검토 허용
   - 예상 효과: WISE 병목 50% 감소

3. 기본 자동 빌드
   - Git 푸시 → 자동 빌드
   - 빌드 실패 알림
   - 예상 효과: 빌드 오류 조기 발견
```

#### 단기 개선 (3개월)
```yaml
4. 단위 테스트 도입
   - TcUnit 프레임워크
   - 신규 코드부터 적용
   - 예상 효과: 버그 30% 감소

5. 병렬 검증
   - 설비 검증 + SQA TEST 동시
   - 예상 효과: 검증 시간 40% 단축

6. 스테이징 환경
   - 테스트 전용 설비
   - 시뮬레이션 환경
   - 예상 효과: 설비 병목 완화
```

#### 중기 개선 (6개월)
```yaml
7. CI/CD 파이프라인
   - 자동 빌드 + 테스트 + 배포
   - 예상 효과: 리드 타임 50% 단축

8. 모니터링 및 알림
   - 실시간 메트릭
   - 자동 알림
   - 예상 효과: 문제 조기 발견

9. 카나리 배포
   - 점진적 배포
   - 자동 롤백
   - 예상 효과: 배포 리스크 80% 감소
```

### 0.11 핵심 개선 포인트 요약

#### Top 5 개선 사항
```yaml
1. Fast Track 긴급 경로 (최우선)
   현재: SCR 비적용 (비공식)
   개선: 공식 Fast Track 프로세스
   효과: 긴급 대응 24시간 → 4시간

2. 병렬 검증 (최대 효과)
   현재: 설비 → SQA (순차 5~8일)
   개선: 설비 + SQA 병렬 (3~4일)
   효과: 검증 시간 40% 단축

3. 자동화 테스트
   현재: 수동 테스트 (재현성 낮음)
   개선: TcUnit + 자동화
   효과: 테스트 시간 60% 단축, 버그 조기 발견

4. 스테이징 환경
   현재: 프로덕션 설비 의존
   개선: 전용 테스트 설비/시뮬레이터
   효과: 설비 접근성 향상, 야간 테스트 불필요

5. 모니터링 + 롤백 자동화
   현재: 수동 롤백 (수시간)
   개선: 자동 롤백 (5분)
   효과: 장애 시간 95% 단축
```

---

## 필수 인프라

### 1. 서버 인프라

#### 1.1 개발/빌드 서버
```yaml
용도: CI/CD 파이프라인, 자동 빌드/테스트
사양:
  - CPU: 8코어 이상 (병렬 빌드)
  - RAM: 32GB 이상
  - Storage: 500GB SSD (빌드 캐시, 아티팩트)
  - OS: Windows Server 2019+ (TwinCAT 호환성)
수량: 최소 2대 (Active-Standby)
예상 비용: 서버당 ₩3,000,000 ~ ₩5,000,000
클라우드 대안: Azure VM (Standard_D8s_v3) 월 ₩500,000
```

#### 1.2 테스트 서버 (스테이징)
```yaml
용도: 통합 테스트, 스테이징 환경
사양:
  - CPU: 4코어
  - RAM: 16GB
  - Storage: 250GB SSD
  - OS: Windows Server 2019+
수량: 최소 2대 (개발/스테이징 분리)
예상 비용: 서버당 ₩2,000,000 ~ ₩3,000,000
클라우드 대안: Azure VM (Standard_D4s_v3) 월 ₩250,000
```

#### 1.3 프로덕션 서버
```yaml
용도: 실제 설비 제어 시스템
사양:
  - CPU: 4-8코어 (실시간 제어)
  - RAM: 16-32GB
  - Storage: 500GB SSD (로그, 백업)
  - OS: Windows 10 IoT Enterprise / Windows Server
  - 이중화: Hot Standby 구성 필수
수량: 최소 2대 (Primary + Backup)
예상 비용: 서버당 ₩5,000,000 ~ ₩8,000,000
특이사항: 설비와 실시간 통신 (EtherCAT, PROFINET 등)
```

#### 1.4 모니터링/로깅 서버
```yaml
용도: 메트릭 수집, 로그 분석, 대시보드
사양:
  - CPU: 4코어
  - RAM: 16GB
  - Storage: 1TB HDD (로그 장기 보관)
  - OS: Linux (Ubuntu 22.04 LTS)
수량: 1대
예상 비용: ₩2,000,000 ~ ₩3,000,000
```

#### 1.5 백업/아티팩트 저장소
```yaml
용도: 코드 백업, 빌드 아티팩트, 버전 관리
사양:
  - Storage: 2TB+ RAID 구성
  - 백업: 외부 NAS 또는 클라우드 스토리지
수량: 1대 + 클라우드 백업
예상 비용: ₩1,500,000 + 클라우드 월 ₩100,000
```

**인프라 총합 (온프레미스):**
- 초기 투자: ₩20,000,000 ~ ₩35,000,000
- 유지보수 (연간): ₩5,000,000 ~ ₩8,000,000

**인프라 총합 (클라우드 하이브리드):**
- 초기 투자: ₩8,000,000 ~ ₩12,000,000 (프로덕션만 온프레미스)
- 운영비 (월간): ₩1,500,000 ~ ₩2,500,000

---

## 소프트웨어 스택

### 2. 핵심 소프트웨어

#### 2.1 버전 관리 시스템
```yaml
필수:
  - Git: 무료
  - Git 서버: Azure DevOps / GitLab / GitHub Enterprise
    Azure DevOps: 기본 무료, 유료 $6/user/month
    GitLab Self-Managed: 무료 (CE) / $19/user/month (Premium)
    GitHub Enterprise: $21/user/month

권장: Azure DevOps (TwinCAT/Windows 통합 우수)
예상 비용 (10명 팀): 월 ₩80,000 ~ ₩300,000
```

#### 2.2 CI/CD 파이프라인
```yaml
옵션 1: Azure Pipelines
  - 기본 무료 (1,800분/월)
  - 병렬 작업: $40/month per parallel job
  - TwinCAT 빌드 지원 우수
  - 예상 비용: 월 ₩150,000 ~ ₩300,000

옵션 2: Jenkins (Self-Hosted)
  - 소프트웨어: 무료
  - 플러그인 설정 복잡
  - 관리 인력 필요
  - 서버 비용: 위 빌드 서버에 포함
  - 예상 비용: 무료 (인력 비용 별도)

옵션 3: GitLab CI/CD
  - GitLab Premium 포함
  - Runner 서버 필요
  - 예상 비용: 월 ₩250,000 ~ ₩400,000

권장: Azure Pipelines (TwinCAT 환경 최적)
```

#### 2.3 자동화 테스트 도구
```yaml
단위 테스트:
  - TcUnit (TwinCAT 단위 테스트): 무료
  - Visual Studio Test: Visual Studio 포함

통합 테스트:
  - TwinCAT Scope View: TwinCAT XAE 포함
  - Custom Test Framework: 자체 개발 필요

설비 검증:
  - TwinCAT HMI: $500 ~ $2,000 (라이센스)
  - LabVIEW (옵션): $1,000 ~ $5,000
  - Custom Test Automation: 개발 필요

예상 비용: ₩2,000,000 ~ ₩5,000,000 (초기)
```

#### 2.4 코드 품질 분석
```yaml
정적 분석:
  - SonarQube Community: 무료
  - SonarQube Developer: $150/year
  - PLC 코드 분석: 제한적 (커스텀 룰 필요)

코드 리뷰:
  - Azure DevOps Pull Request: 포함
  - GitHub Code Review: 포함

보안 스캔:
  - Dependency Check: 무료
  - Snyk: $0 ~ $450/month (팀 규모)
  - WhiteSource: 커스텀 가격

예상 비용: 무료 ~ 월 ₩500,000
```

#### 2.5 모니터링 및 로깅
```yaml
애플리케이션 모니터링:
  - Prometheus: 무료
  - Grafana: 무료
  - Azure Monitor: 종량제 (월 ₩100,000 ~ ₩500,000)

로그 관리:
  - ELK Stack (Elasticsearch, Logstash, Kibana): 무료
    - 관리 복잡, 서버 리소스 많이 소비
  - Azure Log Analytics: 종량제
  - Splunk: $150/GB/month (매우 비쌈)

TwinCAT 전용:
  - TwinCAT EventLogger: 기본 포함
  - Custom Dashboard: 개발 필요

권장: Prometheus + Grafana + ELK Stack
예상 비용: 무료 ~ 월 ₩300,000 (클라우드 사용 시)
```

#### 2.6 배포 자동화
```yaml
카나리/블루-그린 배포:
  - 커스텀 스크립트 개발 필요
  - PowerShell DSC: 무료
  - Ansible: 무료
  - Azure DevOps Deployment Groups: 포함

컨테이너화 (선택):
  - Docker Desktop: 무료 (개인) / $9/user/month (비즈니스)
  - Kubernetes: 복잡도 매우 높음 (PLC 환경에 부적합)

권장: PowerShell + Azure DevOps
예상 비용: 무료 (개발 인력 필요)
```

#### 2.7 TwinCAT 라이센스
```yaml
필수 라이센스:
  - TwinCAT 3 XAE (개발): 무료 (Visual Studio Shell)
  - TwinCAT 3 XAR (런타임): 디바이스당 비용
    - Level 1 (기본 PLC): €100 ~ €500
    - Level 2 (고급 PLC): €500 ~ €1,500
    - NC (Motion): €1,000 ~ €3,000
    - Vision (옵션): €2,000+

개발자 라이선스:
  - Visual Studio Professional: $45/month/user
  - Visual Studio Enterprise: $250/month/user (테스트 도구 포함)

예상 비용:
  - 개발 환경 (5명): 월 ₩300,000 ~ ₩1,500,000
  - 런타임 (10대): ₩5,000,000 ~ ₩20,000,000 (일회성)
```

**소프트웨어 총합:**
- 초기 비용: ₩10,000,000 ~ ₩30,000,000
- 월간 운영비: ₩500,000 ~ ₩2,000,000
- 연간 라이센스: ₩5,000,000 ~ ₩15,000,000

---

## 팀 구성 및 역량

### 3. 필요 인력

#### 3.1 핵심 팀 (최소 구성)

```yaml
DevOps 엔지니어 (1명):
  역할:
    - CI/CD 파이프라인 구축 및 관리
    - 인프라 자동화
    - 모니터링 시스템 구축
  필요 스킬:
    - Azure DevOps / Jenkins
    - PowerShell, Bash 스크립트
    - Git, 버전 관리
    - 네트워크 기본 지식
  연봉: ₩50,000,000 ~ ₩80,000,000

PLC/TwinCAT 개발자 (2-3명):
  역할:
    - TwinCAT 프로젝트 개발
    - 자동화 테스트 작성
    - 코드 리뷰
  필요 스킬:
    - TwinCAT 3 (IEC 61131-3)
    - C++/C# (TwinCAT ADS)
    - 설비 제어 경험
    - Git 기본 사용
  연봉: ₩45,000,000 ~ ₩70,000,000

QA 엔지니어 (1명):
  역할:
    - 테스트 시나리오 작성
    - 자동화 테스트 관리
    - 품질 메트릭 분석
  필요 스킬:
    - TwinCAT 기본 이해
    - 테스트 자동화 도구
    - 설비 검증 경험
  연봉: ₩40,000,000 ~ ₩60,000,000

시스템 관리자 (0.5명, 파트타임 또는 겸직):
  역할:
    - 서버 유지보수
    - 백업/복구
    - 보안 관리
  필요 스킬:
    - Windows Server 관리
    - 네트워크 설정
    - 백업 솔루션
  연봉: ₩35,000,000 ~ ₩55,000,000 (풀타임 기준)
```

#### 3.2 확장 팀 (이상적 구성)

```yaml
추가 인력:
  - 시니어 DevOps 엔지니어: 1명
  - 보안 전문가: 0.5명 (컨설팅)
  - 데이터 분석가: 0.5명 (메트릭 분석)
  - 기술 문서 작성자: 0.5명

총 인건비 (최소):
  - 연간: ₩200,000,000 ~ ₩350,000,000

총 인건비 (확장):
  - 연간: ₩350,000,000 ~ ₩500,000,000
```

#### 3.3 교육 및 훈련

```yaml
초기 교육 (3-6개월):
  - Azure DevOps 교육: ₩2,000,000
  - TwinCAT 고급 과정: ₩3,000,000
  - Git/DevOps 워크샵: ₩1,500,000
  - 보안 교육: ₩1,000,000

지속 교육 (연간):
  - 컨퍼런스 참가: ₩3,000,000
  - 온라인 교육: ₩2,000,000
  - 외부 컨설팅: ₩10,000,000 ~ ₩20,000,000

총 교육 비용:
  - 초기: ₩7,500,000 ~ ₩10,000,000
  - 연간: ₩5,000,000 ~ ₩25,000,000
```

---

## 예산 및 시간

### 4. 총 예산 산정

#### 4.1 Phase 1 (1-2개월): Fast Track + 기본 자동화

```yaml
인프라:
  - 빌드 서버 (클라우드): ₩0 (월비용으로)
  - Git 저장소: ₩0 (Azure DevOps 무료 티어)

소프트웨어:
  - Azure DevOps: ₩200,000
  - Visual Studio 라이센스: ₩600,000

개발:
  - DevOps 엔지니어 (2개월): ₩13,000,000
  - PLC 개발자 지원 (파트타임): ₩5,000,000

교육:
  - 기본 교육: ₩2,000,000

Phase 1 총합: ₩20,800,000

월 운영비: ₩1,000,000

주요 산출물:
  ✓ Fast Track 프로세스 정의
  ✓ 우선순위 분류 시스템
  ✓ 기본 CI/CD 파이프라인
  ✓ 자동 빌드/단위 테스트
```

#### 4.2 Phase 2 (2-3개월): 병렬 검증 + 스테이징

```yaml
인프라:
  - 스테이징 서버: ₩3,000,000
  - 모니터링 서버: ₩2,000,000

소프트웨어:
  - Prometheus + Grafana: ₩0
  - TwinCAT 테스트 도구: ₩2,000,000

개발:
  - DevOps 엔지니어 (3개월): ₩20,000,000
  - QA 엔지니어 (3개월): ₩12,000,000
  - PLC 개발자 (테스트 작성): ₩8,000,000

교육:
  - 테스트 자동화 교육: ₩3,000,000

Phase 2 총합: ₩50,000,000

누적 월 운영비: ₩1,500,000

주요 산출물:
  ✓ 병렬 검증 환경
  ✓ 스테이징 배포 자동화
  ✓ 24시간 모니터링 시스템
  ✓ 자동 롤백 메커니즘 (기본)
```

#### 4.3 Phase 3 (3-4개월): 카나리/블루-그린 + 메트릭

```yaml
인프라:
  - 프로덕션 이중화: ₩12,000,000
  - 로드 밸런서: ₩2,000,000

소프트웨어:
  - 고급 모니터링: ₩3,000,000
  - 대시보드 개발: ₩5,000,000

개발:
  - DevOps 엔지니어 (4개월): ₩27,000,000
  - 시스템 관리자 (4개월): ₩15,000,000
  - PLC 개발자 (통합): ₩10,000,000

외부 컨설팅:
  - 배포 전략 컨설팅: ₩10,000,000
  - 보안 감사: ₩5,000,000

Phase 3 총합: ₩89,000,000

누적 월 운영비: ₩2,500,000

주요 산출물:
  ✓ 카나리 배포 시스템
  ✓ 블루-그린 배포
  ✓ 실시간 메트릭 대시보드
  ✓ 자동 코드 리뷰 통합
  ✓ 보안 스캔 자동화
```

#### 4.4 총 예산 요약

```yaml
초기 구축 (9-10개월):
  Phase 1: ₩20,800,000
  Phase 2: ₩50,000,000
  Phase 3: ₩89,000,000
  예비비 (15%): ₩24,000,000
  
  총 초기 투자: ₩183,800,000 ~ ₩200,000,000

연간 운영비:
  - 월 운영비: ₩2,500,000 ~ ₩3,500,000
  - 연간: ₩30,000,000 ~ ₩42,000,000
  
  인건비: ₩200,000,000 ~ ₩350,000,000
  라이센스: ₩5,000,000 ~ ₩15,000,000
  교육/개선: ₩5,000,000 ~ ₩25,000,000
  
  총 연간 운영: ₩240,000,000 ~ ₩430,000,000

3년 총 비용 (TCO):
  초기 + (연간 × 3) = ₩900,000,000 ~ ₩1,500,000,000
```

---

## 단계별 구축 계획

### 5. 현실적 로드맵

#### 5.1 Phase 1: 기초 구축 (1-2개월)

**Week 1-2: 환경 설정**
```yaml
작업:
  - Azure DevOps 계정 생성 및 설정
  - Git 저장소 구조 설계
  - 개발 서버 프로비저닝 (클라우드)
  - 팀 온보딩 및 권한 설정

체크리스트:
  ☐ Azure DevOps 프로젝트 생성
  ☐ Git 브랜치 전략 수립 (GitFlow)
  ☐ 빌드 에이전트 설치
  ☐ TwinCAT 개발 환경 설정
  ☐ 기본 문서화

리스크:
  - Azure DevOps 미숙: 외부 컨설팅 2-3일 필요
  - TwinCAT 버전 호환성: 사전 테스트 필수
```

**Week 3-4: Fast Track 프로세스**
```yaml
작업:
  - 우선순위 분류 기준 문서화
  - Fast Track 워크플로우 정의
  - 승인 프로세스 간소화
  - 템플릿 및 체크리스트 작성

산출물:
  ✓ Fast Track 가이드 문서
  ✓ 우선순위 매트릭스
  ✓ 승인 템플릿

리스크:
  - 기존 프로세스와 충돌: 리더십 승인 필요
  - 팀 저항: 충분한 교육 및 설득 필요
```

**Week 5-8: 기본 CI/CD**
```yaml
작업:
  - 자동 빌드 파이프라인 구축
  - TcUnit 단위 테스트 통합
  - 빌드 실패 알림 설정
  - 아티팩트 저장 자동화

기술 스택:
  - Azure Pipelines YAML
  - PowerShell 스크립트
  - TwinCAT CLI 도구

체크리스트:
  ☐ 빌드 파이프라인 YAML 작성
  ☐ TwinCAT 프로젝트 자동 빌드 성공
  ☐ 단위 테스트 실행 자동화
  ☐ 빌드 실패 시 이메일/Slack 알림
  ☐ 빌드 히스토리 보관

리스크:
  - TwinCAT CLI 제한: 일부 수동 작업 불가피
  - 라이센스 이슈: 빌드 서버 라이센스 확인
  - 복잡한 프로젝트: 빌드 시간 최적화 필요
```

#### 5.2 Phase 2: 검증 강화 (2-3개월)

**Week 9-12: 테스트 환경 구축**
```yaml
작업:
  - 스테이징 서버 설정
  - 가상 PLC 환경 구축 (TwinCAT Runtime)
  - 테스트 데이터 준비
  - 자동화 테스트 프레임워크

기술 결정:
  - 물리적 설비 vs 시뮬레이션
    → 초기: 시뮬레이션 (빠름, 저비용)
    → 후기: 물리적 검증 필수

체크리스트:
  ☐ 스테이징 서버 준비
  ☐ TwinCAT Runtime 설치 및 활성화
  ☐ 네트워크 격리 (프로덕션과 분리)
  ☐ 테스트 시나리오 10개 이상 작성
  ☐ 자동화 테스트 실행 성공

리스크:
  - 시뮬레이션 한계: 실제 설비와 차이
  - 네트워크 설정: IT 팀 협조 필요
  - 데이터 동기화: 프로덕션 데이터 복제 전략
```

**Week 13-16: 병렬 검증**
```yaml
작업:
  - 설비 검증 자동화
  - SQA 테스트 병렬 실행
  - 보안 스캔 통합
  - 통합 검증 게이트 구현

병렬화 전략:
  ├─ 설비 검증: 전용 설비 또는 시뮬레이터
  ├─ SQA 테스트: 독립적 테스트 환경
  └─ 보안 스캔: 소스 코드 정적 분석

체크리스트:
  ☐ 3가지 검증 병렬 실행 확인
  ☐ 각 검증 독립적으로 실행 가능
  ☐ 실패 시 명확한 리포트
  ☐ 검증 시간 측정 (SLA 준수)

리스크:
  - 리소스 경쟁: 충분한 서버 필요
  - 테스트 불안정: Flaky 테스트 제거
  - 결과 통합: 일관된 포맷 필요
```

**Week 17-20: 모니터링 및 롤백**
```yaml
작업:
  - Prometheus + Grafana 설치
  - TwinCAT 메트릭 수집 (CPU, 사이클 타임)
  - 알림 규칙 설정 (임계값)
  - 자동 롤백 스크립트

메트릭 수집:
  - 시스템: CPU, 메모리, 디스크
  - TwinCAT: 사이클 타임, 태스크 지터
  - 애플리케이션: 에러 카운트, 처리량

체크리스트:
  ☐ Prometheus 데이터 수집 확인
  ☐ Grafana 대시보드 5개 이상
  ☐ 알림 규칙 10개 이상 설정
  ☐ 알림 수신 확인 (이메일/Slack)
  ☐ 롤백 테스트 성공

리스크:
  - TwinCAT 메트릭 제한: ADS API 활용 필요
  - 알림 피로: 임계값 튜닝 필수
  - 롤백 복잡도: 설비 상태 고려
```

#### 5.3 Phase 3: 고급 배포 (3-4개월)

**Week 21-26: 카나리 배포**
```yaml
작업:
  - 로드 밸런서 설정
  - 트래픽 라우팅 로직
  - 카나리 메트릭 정의
  - 자동 롤백 트리거

주의사항:
  - PLC 환경에서 "트래픽"의 의미
    → 일부 설비만 새 버전 적용
    → 예: 10대 중 1대만 업데이트
  - 설비 특성상 롤백 복잡
    → 상태 머신 고려 필수

체크리스트:
  ☐ 카나리 배포 정책 문서화
  ☐ 1대 설비 테스트 성공
  ☐ 메트릭 비교 (기존 vs 카나리)
  ☐ 자동 롤아웃 (10% → 50% → 100%)
  ☐ 실패 시 자동 롤백 확인

리스크:
  - 설비 이질성: 동일 설비여도 차이 존재
  - 상태 불일치: 버전 혼재 시 문제
  - 긴 검증 시간: 24-48시간 필요
```

**Week 27-32: 메트릭 및 최적화**
```yaml
작업:
  - 대시보드 고도화
  - 리드 타임 추적
  - 품질 지표 자동 계산
  - 프로세스 개선 제안

핵심 메트릭:
  - DORA 메트릭:
    ├─ Deployment Frequency (배포 빈도)
    ├─ Lead Time for Changes (변경 리드 타임)
    ├─ Change Failure Rate (변경 실패율)
    └─ Time to Restore Service (복구 시간)

체크리스트:
  ☐ 메트릭 자동 수집 및 계산
  ☐ 주간 리포트 자동 생성
  ☐ 병목 지점 식별
  ☐ 개선 제안 5개 이상

리스크:
  - 데이터 품질: 수동 입력 오류
  - 해석 오류: 컨텍스트 필요
  - 개선 저항: 문화적 변화 필요
```

**Week 33-40: 안정화 및 문서화**
```yaml
작업:
  - 전체 프로세스 검증
  - 사용자 교육 (전체 팀)
  - 운영 매뉴얼 작성
  - 트러블슈팅 가이드

산출물:
  ✓ 운영 매뉴얼 (100페이지+)
  ✓ 트러블슈팅 가이드
  ✓ FAQ 문서
  ✓ 비디오 튜토리얼

체크리스트:
  ☐ 전체 워크플로우 E2E 테스트
  ☐ 모든 팀원 교육 완료
  ☐ 문서 검토 및 승인
  ☐ 비상 연락망 구축
  ☐ 프로덕션 전환 승인

리스크:
  - 문서 부족: 지속적 업데이트 필요
  - 교육 불충분: 실습 중심 교육 필수
  - 저항: 점진적 전환 고려
```

---

## 현실적 제약사항

### 6. 주요 제약 및 대응 방안

#### 6.1 TwinCAT 특수성

**제약사항:**
```yaml
1. 실시간 제어:
   문제: 배포 중 설비 중단 불가
   영향: 카나리/블루-그린 배포 제한적
   대응:
     - 계획된 다운타임 활용 (야간/주말)
     - Hot Swap 불가 → 빠른 재시작 전략
     - 설비 이중화 (Primary/Backup)

2. 라이센스 비용:
   문제: 런타임 라이센스 고가
   영향: 테스트 환경 구축 비용 증가
   대응:
     - 개발 라이센스 공유
     - 시뮬레이션 활용 (물리적 검증은 최소화)
     - 클라우드 VM 동적 할당

3. CLI 제한:
   문제: TwinCAT CLI 기능 제한적
   영향: 완전 자동화 어려움
   대응:
     - Visual Studio Automation API 활용
     - PowerShell COM 인터페이스
     - 일부 수동 작업 허용 (문서화)

4. 설비 의존성:
   문제: 실제 설비 없이 완전한 테스트 불가
   영향: 설비 검증 시간 길어짐
   대응:
     - 시뮬레이터 활용 (초기)
     - 테스트 설비 전용 할당
     - 야간 자동 테스트
```

#### 6.2 조직적 제약

**제약사항:**
```yaml
1. 기존 프로세스 변경 저항:
   문제: "지금도 잘 되는데 왜 바꾸나"
   대응:
     - 파일럿 프로젝트로 효과 증명
     - 점진적 도입 (Fast Track부터)
     - 경영진 지원 확보
     - 성공 사례 공유

2. 스킬 부족:
   문제: DevOps 경험 부족한 팀
   대응:
     - 외부 컨설팅 (초기 3-6개월)
     - 집중 교육 프로그램
     - 페어 프로그래밍
     - 내부 전문가 양성

3. 시간 부족:
   문제: 업무 병행하며 구축 어려움
   대응:
     - 전담 인력 배치 (최소 DevOps 1명)
     - 업무 재분배
     - 야근/주말 작업 → 보상
     - 외부 인력 활용

4. 예산 승인:
   문제: 2억 예산 확보 어려움
   대응:
     - ROI 계산 (품질 향상, 시간 절감)
     - 단계별 예산 요청
     - 무료/오픈소스 우선 활용
     - 클라우드로 초기 투자 최소화
```

#### 6.3 기술적 제약

**제약사항:**
```yaml
1. 레거시 코드:
   문제: 기존 코드 테스트 어려움
   대응:
     - 신규 코드부터 적용
     - 점진적 리팩토링
     - 커버리지 목표 낮게 (초기 30%)

2. 네트워크 제약:
   문제: 설비 네트워크 격리 (보안)
   대응:
     - VPN/점프 서버
     - 별도 배포 채널
     - 오프라인 배포 패키지

3. 성능:
   문제: 빌드/테스트 시간 오래 걸림
   대응:
     - 증분 빌드
     - 병렬 빌드 (멀티코어)
     - 캐싱 전략
     - 야간 배치 빌드

4. 모니터링 오버헤드:
   문제: 실시간 제어에 영향
   대응:
     - 비침입적 모니터링
     - 샘플링 (1초 단위)
     - 별도 모니터링 태스크
```

#### 6.4 운영 리스크

**주요 리스크:**
```yaml
1. 프로덕션 장애:
   확률: 중 (30%)
   영향: 치명적
   대응:
     - 철저한 테스트
     - 단계적 배포 (카나리)
     - 빠른 롤백 (5분 이내)
     - 24/7 온콜 체계

2. 데이터 손실:
   확률: 저 (10%)
   영향: 높음
   대응:
     - 자동 백업 (일 1회)
     - 버전 관리 (Git)
     - 오프사이트 백업
     - 복구 테스트 (월 1회)

3. 보안 침해:
   확률: 저 (5%)
   영향: 치명적
   대응:
     - 네트워크 분리
     - 접근 제어 (RBAC)
     - 정기 보안 감사
     - 패치 관리

4. 인력 이탈:
   확률: 중 (20%)
   영향: 높음
   대응:
     - 문서화 철저
     - 크로스 트레이닝
     - 지식 공유 세션
     - 온보딩 프로세스
```

---

## 최소 실행 가능 제품 (MVP)

### 7. 현실적 시작점

만약 **예산/시간이 매우 제한적**이라면:

#### 7.1 초미니멀 버전 (1개월, ₩5,000,000)

```yaml
목표: Fast Track + 기본 자동 빌드만

환경:
  - Azure DevOps 무료 티어
  - 기존 개발 PC를 빌드 에이전트로 활용
  - 클라우드 사용 안 함 (비용 제로)

구현:
  1. Git 저장소 설정 (1일)
  2. Fast Track 프로세스 문서화 (3일)
  3. 기본 빌드 파이프라인 (1주)
  4. 이메일 알림 (1일)

비용:
  - 소프트웨어: ₩0 (무료 티어)
  - 인력: 1명 × 1개월 = ₩5,000,000
  - 교육: 온라인 자료 활용

효과:
  ✓ Fast Track으로 긴급 대응 50% 단축
  ✓ 빌드 자동화로 실수 80% 감소
  ✓ 버전 관리로 추적성 확보

한계:
  ✗ 자동 테스트 없음
  ✗ 배포 자동화 없음
  ✗ 모니터링 없음
```

#### 7.2 미니멀 버전 (3개월, ₩20,000,000)

```yaml
목표: MVP + 기본 테스트 + 스테이징

환경:
  - Azure DevOps 유료 (₩500,000)
  - 스테이징 서버 1대 (₩3,000,000)
  - 기본 모니터링

구현:
  - 초미니멀 + 아래 추가
  5. 단위 테스트 자동화 (2주)
  6. 스테이징 배포 (2주)
  7. 기본 모니터링 (1주)

비용:
  - 인프라: ₩3,500,000
  - 소프트웨어: ₩500,000
  - 인력: 1.5명 × 3개월 = ₩16,000,000

효과:
  ✓ 초미니멀 효과 +
  ✓ 테스트 커버리지 30%
  ✓ 프로덕션 배포 전 검증
  ✓ 기본 메트릭 수집

이후 확장:
  → 3개월마다 예산 확보하여 점진적 개선
```

---

## 성공 지표 (KPI)

### 8. 측정 가능한 목표

```yaml
Phase 1 완료 후:
  ✓ 긴급 수정 대응 시간: 24시간 → 4시간
  ✓ 빌드 실패율: 30% → 5%
  ✓ 수동 빌드 시간: 2시간 → 10분

Phase 2 완료 후:
  ✓ 테스트 커버리지: 0% → 40%
  ✓ 프로덕션 버그: 월 10건 → 3건
  ✓ 검증 시간: 5일 → 2일

Phase 3 완료 후:
  ✓ 배포 빈도: 월 1회 → 주 1회
  ✓ 배포 실패율: 20% → 2%
  ✓ 장애 복구 시간: 4시간 → 30분
  ✓ 리드 타임: 30일 → 5일

ROI 계산:
  투자: ₩200,000,000
  절감 (연간):
    - 긴급 대응 시간 절감: ₩50,000,000
    - 품질 이슈 감소: ₩100,000,000
    - 생산성 향상: ₩80,000,000
  
  회수 기간: 약 1년
  3년 ROI: 350%
```

---

## 결론 및 권장사항

### 9. 현실적 접근 방법

```yaml
권장 시작 방법:

1. 평가 및 준비 (1개월):
   - 현재 프로세스 문서화
   - 팀 스킬 평가
   - 예산 확보 노력
   - 경영진 설득 자료 준비

2. 파일럿 프로젝트 (2-3개월):
   - 작은 프로젝트 선정
   - 미니멀 버전 구축
   - 효과 측정 및 공유
   - 팀 교육 및 피드백

3. 점진적 확대 (6-12개월):
   - 성공 사례 기반 확대
   - 추가 예산 확보
   - 전체 프로세스 적용
   - 지속적 개선

핵심 성공 요소:
  ✓ 경영진 지원
  ✓ 전담 인력 (DevOps 엔지니어)
  ✓ 충분한 교육
  ✓ 점진적 접근
  ✓ 빠른 피드백

실패 요인:
  ✗ 한 번에 모든 것 구현
  ✗ 인력/예산 부족
  ✗ 기존 프로세스 무시
  ✗ 교육 부족
  ✗ 측정 없이 진행
```

---

## 참고 자료

### 10. 추가 학습 자료

```yaml
TwinCAT 관련:
  - Beckhoff Information System (공식 문서)
  - TwinCAT 3 Training (Beckhoff 교육)
  - TwinCAT GitHub Examples

DevOps 관련:
  - Azure DevOps Documentation
  - The Phoenix Project (책)
  - Accelerate (책 - DORA 메트릭)
  - DevOps Handbook (책)

모니터링:
  - Prometheus Documentation
  - Grafana Best Practices
  - SRE Workbook (Google)

커뮤니티:
  - PLCopen User Group
  - TwinCAT Community Forum
  - Azure DevOps Community
```

---

**문서 버전:** 1.0  
**작성일:** 2025-11-26  
**업데이트:** 프로젝트 진행에 따라 분기별 업데이트  
**담당자:** DevOps 팀
