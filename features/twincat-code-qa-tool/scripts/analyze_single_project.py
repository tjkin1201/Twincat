#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TwinCAT ë‹¨ì¼ í”„ë¡œì íŠ¸ QA ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì½”ë“œ í’ˆì§ˆ, ì ì¬ì  ë²„ê·¸, ì½”ë”© í‘œì¤€ ê²€ì‚¬
"""

import os
import re
import sys
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from collections import defaultdict
import json

@dataclass
class QAIssue:
    """QA ì´ìŠˆ"""
    rule_id: str
    severity: str  # Critical, Warning, Info
    category: str  # Safety, Performance, Maintainability, Style
    file_path: str
    line: int
    message: str
    code_snippet: str = ""
    suggestion: str = ""

@dataclass
class FileStats:
    """íŒŒì¼ í†µê³„"""
    file_path: str
    file_type: str  # POU, GVL, DUT
    pou_type: str = ""  # PROGRAM, FUNCTION_BLOCK, FUNCTION
    name: str = ""
    lines_of_code: int = 0
    lines_of_comment: int = 0
    variable_count: int = 0
    complexity: int = 0  # ìˆœí™˜ ë³µì¡ë„ ì¶”ì •
    issues: List[QAIssue] = field(default_factory=list)

class TwinCATSingleProjectAnalyzer:
    """TwinCAT ë‹¨ì¼ í”„ë¡œì íŠ¸ ë¶„ì„ê¸°"""

    def __init__(self, project_path: str):
        self.project_path = Path(project_path)
        self.files: List[FileStats] = []
        self.qa_issues: List[QAIssue] = []
        self.global_vars: Dict[str, Dict] = {}
        self.functions: Dict[str, Dict] = {}

    def analyze(self) -> Dict:
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print(f"{'='*60}")
        print(f"TwinCAT í”„ë¡œì íŠ¸ QA ë¶„ì„")
        print(f"{'='*60}")
        print(f"ë¶„ì„ ëŒ€ìƒ: {self.project_path}")
        print(f"ë¶„ì„ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()

        # 1. íŒŒì¼ ìˆ˜ì§‘
        self._collect_files()

        # 2. ê° íŒŒì¼ ë¶„ì„
        self._analyze_files()

        # 3. ì „ì—­ ë¶„ì„ (í¬ë¡œìŠ¤ íŒŒì¼)
        self._global_analysis()

        # 4. ë¦¬í¬íŠ¸ ìƒì„±
        return self._generate_report()

    def _collect_files(self):
        """ë¶„ì„í•  íŒŒì¼ ìˆ˜ì§‘"""
        print("[1/4] íŒŒì¼ ìˆ˜ì§‘ ì¤‘...")

        extensions = {'.TcPOU': 'POU', '.TcGVL': 'GVL', '.TcDUT': 'DUT'}

        for ext, file_type in extensions.items():
            for file_path in self.project_path.rglob(f'*{ext}'):
                self.files.append(FileStats(
                    file_path=str(file_path.relative_to(self.project_path)),
                    file_type=file_type
                ))

        print(f"  - TcPOU: {len([f for f in self.files if f.file_type == 'POU'])}ê°œ")
        print(f"  - TcGVL: {len([f for f in self.files if f.file_type == 'GVL'])}ê°œ")
        print(f"  - TcDUT: {len([f for f in self.files if f.file_type == 'DUT'])}ê°œ")
        print(f"  - ì´: {len(self.files)}ê°œ")
        print()

    def _analyze_files(self):
        """ê° íŒŒì¼ ë¶„ì„"""
        print("[2/4] íŒŒì¼ë³„ ë¶„ì„ ì¤‘...")

        for i, file_stat in enumerate(self.files):
            full_path = self.project_path / file_stat.file_path
            try:
                content = full_path.read_text(encoding='utf-8', errors='ignore')

                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                self._extract_file_info(file_stat, content)

                # QA ê·œì¹™ ì ìš©
                self._apply_qa_rules(file_stat, content)

            except Exception as e:
                print(f"    ê²½ê³ : {file_stat.file_path} ë¶„ì„ ì‹¤íŒ¨ - {e}")

            # ì§„í–‰ë¥  í‘œì‹œ
            if (i + 1) % 20 == 0 or i == len(self.files) - 1:
                print(f"  ì§„í–‰: {i+1}/{len(self.files)} ({(i+1)*100//len(self.files)}%)")

        print()

    def _extract_file_info(self, file_stat: FileStats, content: str):
        """íŒŒì¼ ì •ë³´ ì¶”ì¶œ"""
        # POU íƒ€ì… ë° ì´ë¦„ ì¶”ì¶œ
        if file_stat.file_type == 'POU':
            if match := re.search(r'<POU\s+Name="([^"]+)"[^>]*>', content):
                file_stat.name = match.group(1)

            declaration = self._extract_section(content, 'Declaration')
            if 'PROGRAM' in declaration:
                file_stat.pou_type = 'PROGRAM'
            elif 'FUNCTION_BLOCK' in declaration:
                file_stat.pou_type = 'FUNCTION_BLOCK'
            elif 'FUNCTION' in declaration:
                file_stat.pou_type = 'FUNCTION'

        elif file_stat.file_type == 'GVL':
            if match := re.search(r'<GVL\s+Name="([^"]+)"', content):
                file_stat.name = match.group(1)

        elif file_stat.file_type == 'DUT':
            if match := re.search(r'<DUT\s+Name="([^"]+)"', content):
                file_stat.name = match.group(1)

        # ì½”ë“œ ë¼ì¸ ìˆ˜
        st_code = self._extract_section(content, 'ST')
        declaration = self._extract_section(content, 'Declaration')
        all_code = declaration + '\n' + st_code

        lines = all_code.split('\n')
        file_stat.lines_of_code = len([l for l in lines if l.strip() and not l.strip().startswith('//')])
        file_stat.lines_of_comment = len([l for l in lines if l.strip().startswith('//')])

        # ë³€ìˆ˜ ìˆ˜
        file_stat.variable_count = len(re.findall(r'^\s*\w+\s*:\s*\w+', all_code, re.MULTILINE))

        # ìˆœí™˜ ë³µì¡ë„ ì¶”ì • (ë¶„ê¸°ë¬¸ ìˆ˜)
        file_stat.complexity = len(re.findall(r'\b(IF|ELSIF|CASE|FOR|WHILE|REPEAT)\b', st_code, re.IGNORECASE))

    def _apply_qa_rules(self, file_stat: FileStats, content: str):
        """QA ê·œì¹™ ì ìš©"""
        declaration = self._extract_section(content, 'Declaration')
        st_code = self._extract_section(content, 'ST')

        # ì„ ì–¸ë¶€ ë¶„ì„
        self._check_declaration_rules(file_stat, declaration)

        # êµ¬í˜„ë¶€ ë¶„ì„
        self._check_implementation_rules(file_stat, st_code)

        # ì „ì²´ ì½”ë“œ ë¶„ì„
        self._check_general_rules(file_stat, declaration + '\n' + st_code)

    def _check_declaration_rules(self, file_stat: FileStats, declaration: str):
        """ì„ ì–¸ë¶€ QA ê·œì¹™"""
        lines = declaration.split('\n')

        for line_num, line in enumerate(lines, 1):
            # QA001: ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ë³€ìˆ˜ (Critical íƒ€ì…ë§Œ)
            if self._is_uninitialized_critical_var(line):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA001",
                    severity="Critical",
                    category="Safety",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ì¤‘ìš” ë³€ìˆ˜ (REAL/LREAL/í¬ì¸í„°)",
                    code_snippet=line.strip(),
                    suggestion="ì„ ì–¸ ì‹œ ì´ˆê¸°ê°’ì„ ëª…ì‹œí•˜ì„¸ìš”: var : TYPE := ì´ˆê¸°ê°’;"
                ))

            # QA003: ë°°ì—´ ì„ ì–¸ ê²€ì‚¬
            if self._is_large_array(line):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA003",
                    severity="Warning",
                    category="Performance",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="ëŒ€ìš©ëŸ‰ ë°°ì—´ ì„ ì–¸ ê°ì§€",
                    code_snippet=line.strip(),
                    suggestion="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê²€í† í•˜ì„¸ìš”"
                ))

            # QA004: í¬ì¸í„° ë³€ìˆ˜
            if re.search(r':\s*POINTER\s+TO\b', line, re.IGNORECASE):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA004",
                    severity="Warning",
                    category="Safety",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="í¬ì¸í„° ë³€ìˆ˜ ì‚¬ìš© - NULL ì²´í¬ í•„ìˆ˜",
                    code_snippet=line.strip(),
                    suggestion="ì‚¬ìš© ì „ ë°˜ë“œì‹œ NULL ì²´í¬ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”"
                ))

            # QA016: ëª…ëª… ê·œì¹™ ê²€ì‚¬
            naming_issue = self._check_naming(line, file_stat.file_type)
            if naming_issue:
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA016",
                    severity="Info",
                    category="Style",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message=f"ëª…ëª… ê·œì¹™: {naming_issue}",
                    code_snippet=line.strip(),
                    suggestion="í—ê°€ë¦¬ì•ˆ í‘œê¸°ë²• ë˜ëŠ” í”„ë¡œì íŠ¸ ëª…ëª… ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”"
                ))

    def _check_implementation_rules(self, file_stat: FileStats, st_code: str):
        """êµ¬í˜„ë¶€ QA ê·œì¹™"""
        lines = st_code.split('\n')

        # ì¤‘ì²© ê¹Šì´ ì¶”ì 
        nesting_depth = 0
        max_nesting = 0

        for line_num, line in enumerate(lines, 1):
            # ì¤‘ì²© ê¹Šì´ ê³„ì‚°
            nesting_depth += len(re.findall(r'\b(IF|FOR|WHILE|CASE|REPEAT)\b', line, re.IGNORECASE))
            nesting_depth -= len(re.findall(r'\b(END_IF|END_FOR|END_WHILE|END_CASE|UNTIL)\b', line, re.IGNORECASE))
            max_nesting = max(max_nesting, nesting_depth)

            # QA002: íƒ€ì… ì¶•ì†Œ ë³€í™˜
            type_issue = self._check_type_narrowing(line)
            if type_issue:
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA002",
                    severity="Critical",
                    category="Safety",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message=f"ìœ„í—˜í•œ íƒ€ì… ë³€í™˜: {type_issue}",
                    code_snippet=line.strip(),
                    suggestion="LIMIT í•¨ìˆ˜ë¡œ ë²”ìœ„ ê²€ì¦ í›„ ë³€í™˜í•˜ì„¸ìš”"
                ))

            # QA005: REAL ì§ì ‘ ë¹„êµ
            if self._check_real_comparison(line):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA005",
                    severity="Critical",
                    category="Safety",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="ì‹¤ìˆ˜í˜•(REAL/LREAL) ì§ì ‘ ë“±í˜¸ ë¹„êµ",
                    code_snippet=line.strip(),
                    suggestion="ABS(a - b) < epsilon í˜•íƒœë¡œ ë¹„êµí•˜ì„¸ìš”"
                ))

            # QA006: 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ê°€ëŠ¥ì„±
            if self._check_division_by_zero(line):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA006",
                    severity="Critical",
                    category="Safety",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ê°€ëŠ¥ì„±",
                    code_snippet=line.strip(),
                    suggestion="ë‚˜ëˆ„ê¸° ì „ ë¶„ëª¨ê°€ 0ì´ ì•„ë‹Œì§€ í™•ì¸í•˜ì„¸ìš”"
                ))

            # QA007: ë§¤ì§ ë„˜ë²„
            magic = self._check_magic_number(line)
            if magic:
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA007",
                    severity="Warning",
                    category="Maintainability",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message=f"ë§¤ì§ ë„˜ë²„ ì‚¬ìš©: {magic}",
                    code_snippet=line.strip(),
                    suggestion="ìƒìˆ˜(CONSTANT)ë¡œ ì •ì˜í•˜ì„¸ìš”"
                ))

            # QA010: í•˜ë“œì½”ë”©ëœ ì‹œê°„ê°’
            if self._check_hardcoded_time(line):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA010",
                    severity="Warning",
                    category="Maintainability",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="í•˜ë“œì½”ë”©ëœ ì‹œê°„ê°’",
                    code_snippet=line.strip(),
                    suggestion="íŒŒë¼ë¯¸í„° ë˜ëŠ” ìƒìˆ˜ë¡œ ì •ì˜í•˜ì„¸ìš”"
                ))

            # QA011: ë¹ˆ ì˜ˆì™¸ ì²˜ë¦¬
            if re.search(r'\bELSE\s*;', line, re.IGNORECASE):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA011",
                    severity="Warning",
                    category="Safety",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="ë¹ˆ ELSE ë¸”ë¡",
                    code_snippet=line.strip(),
                    suggestion="ì˜ˆì™¸ ì²˜ë¦¬ ë¡œì§ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì£¼ì„ìœ¼ë¡œ ì˜ë„ë¥¼ ëª…ì‹œí•˜ì„¸ìš”"
                ))

            # QA012: TODO/FIXME ì£¼ì„
            if re.search(r'(//|/\*)\s*(TODO|FIXME|XXX|HACK)', line, re.IGNORECASE):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA012",
                    severity="Info",
                    category="Maintainability",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="ë¯¸ì™„ë£Œ ì‘ì—… í‘œì‹œ ë°œê²¬",
                    code_snippet=line.strip(),
                    suggestion="ë¦´ë¦¬ìŠ¤ ì „ í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤"
                ))

            # QA013: ì£¼ì„ ì²˜ë¦¬ëœ ì½”ë“œ
            if self._is_commented_code(line):
                self._add_issue(file_stat, QAIssue(
                    rule_id="QA013",
                    severity="Info",
                    category="Maintainability",
                    file_path=file_stat.file_path,
                    line=line_num,
                    message="ì£¼ì„ ì²˜ë¦¬ëœ ì½”ë“œ",
                    code_snippet=line.strip()[:80],
                    suggestion="ë¶ˆí•„ìš”í•œ ì½”ë“œëŠ” ì‚­ì œí•˜ì„¸ìš” (ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ í™œìš©)"
                ))

        # QA008: ê³¼ë„í•œ ì¤‘ì²©
        if max_nesting > 4:
            self._add_issue(file_stat, QAIssue(
                rule_id="QA008",
                severity="Warning",
                category="Maintainability",
                file_path=file_stat.file_path,
                line=0,
                message=f"ê³¼ë„í•œ ì¤‘ì²© ê¹Šì´: {max_nesting}ë‹¨ê³„",
                suggestion="í•¨ìˆ˜ ë¶„ë¦¬ ë˜ëŠ” early return íŒ¨í„´ì„ ì‚¬ìš©í•˜ì„¸ìš”"
            ))

    def _check_general_rules(self, file_stat: FileStats, all_code: str):
        """ì „ì²´ ì½”ë“œ ê·œì¹™"""
        # QA009: ê¸´ í•¨ìˆ˜/í”„ë¡œê·¸ë¨
        if file_stat.lines_of_code > 500:
            self._add_issue(file_stat, QAIssue(
                rule_id="QA009",
                severity="Warning",
                category="Maintainability",
                file_path=file_stat.file_path,
                line=0,
                message=f"ì½”ë“œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤: {file_stat.lines_of_code}ì¤„",
                suggestion="500ì¤„ ì´í•˜ë¡œ ë¶„ë¦¬ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤"
            ))

        # QA014: ë†’ì€ ìˆœí™˜ ë³µì¡ë„
        if file_stat.complexity > 15:
            self._add_issue(file_stat, QAIssue(
                rule_id="QA014",
                severity="Warning",
                category="Maintainability",
                file_path=file_stat.file_path,
                line=0,
                message=f"ë†’ì€ ìˆœí™˜ ë³µì¡ë„: {file_stat.complexity}",
                suggestion="í•¨ìˆ˜ë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”"
            ))

        # QA015: ì£¼ì„ ë¶€ì¡±
        if file_stat.lines_of_code > 50 and file_stat.lines_of_comment < file_stat.lines_of_code * 0.1:
            self._add_issue(file_stat, QAIssue(
                rule_id="QA015",
                severity="Info",
                category="Maintainability",
                file_path=file_stat.file_path,
                line=0,
                message="ì£¼ì„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ (ì½”ë“œ ëŒ€ë¹„ 10% ë¯¸ë§Œ)",
                suggestion="ë³µì¡í•œ ë¡œì§ì— ì£¼ì„ì„ ì¶”ê°€í•˜ì„¸ìš”"
            ))

    def _global_analysis(self):
        """ì „ì—­ ë¶„ì„"""
        print("[3/4] ì „ì—­ ë¶„ì„ ì¤‘...")

        # ë¯¸ì‚¬ìš© ì „ì—­ ë³€ìˆ˜ ê²€ì‚¬ ë“±
        # (í˜„ì¬ëŠ” ê¸°ë³¸ ë¶„ì„ë§Œ ìˆ˜í–‰)

        total_issues = len(self.qa_issues)
        critical = len([i for i in self.qa_issues if i.severity == 'Critical'])
        warning = len([i for i in self.qa_issues if i.severity == 'Warning'])
        info = len([i for i in self.qa_issues if i.severity == 'Info'])

        print(f"  - ì´ ì´ìŠˆ: {total_issues}ê°œ")
        print(f"  - Critical: {critical}ê°œ")
        print(f"  - Warning: {warning}ê°œ")
        print(f"  - Info: {info}ê°œ")
        print()

    def _generate_report(self) -> Dict:
        """ë¦¬í¬íŠ¸ ìƒì„±"""
        print("[4/4] ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

        # ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
        by_category = defaultdict(list)
        for issue in self.qa_issues:
            by_category[issue.category].append(issue)

        # íŒŒì¼ë³„ ì§‘ê³„
        by_file = defaultdict(list)
        for issue in self.qa_issues:
            by_file[issue.file_path].append(issue)

        # ê·œì¹™ë³„ ì§‘ê³„
        by_rule = defaultdict(list)
        for issue in self.qa_issues:
            by_rule[issue.rule_id].append(issue)

        report = {
            "generated_at": datetime.now().isoformat(),
            "project_path": str(self.project_path),
            "summary": {
                "total_files": len(self.files),
                "total_pou": len([f for f in self.files if f.file_type == 'POU']),
                "total_gvl": len([f for f in self.files if f.file_type == 'GVL']),
                "total_dut": len([f for f in self.files if f.file_type == 'DUT']),
                "total_lines": sum(f.lines_of_code for f in self.files),
                "total_issues": len(self.qa_issues),
                "critical_count": len([i for i in self.qa_issues if i.severity == 'Critical']),
                "warning_count": len([i for i in self.qa_issues if i.severity == 'Warning']),
                "info_count": len([i for i in self.qa_issues if i.severity == 'Info']),
                "by_category": {k: len(v) for k, v in by_category.items()},
            },
            "files": [
                {
                    "path": f.file_path,
                    "type": f.file_type,
                    "pou_type": f.pou_type,
                    "name": f.name,
                    "lines": f.lines_of_code,
                    "complexity": f.complexity,
                    "issue_count": len([i for i in self.qa_issues if i.file_path == f.file_path])
                }
                for f in self.files
            ],
            "issues_by_rule": {
                rule_id: {
                    "count": len(issues),
                    "severity": issues[0].severity if issues else "",
                    "category": issues[0].category if issues else "",
                }
                for rule_id, issues in sorted(by_rule.items())
            },
            "issues": [
                {
                    "rule_id": i.rule_id,
                    "severity": i.severity,
                    "category": i.category,
                    "file": i.file_path,
                    "line": i.line,
                    "message": i.message,
                    "code": i.code_snippet,
                    "suggestion": i.suggestion
                }
                for i in self.qa_issues
            ]
        }

        return report

    # === Helper Methods ===

    def _extract_section(self, content: str, section: str) -> str:
        """XMLì—ì„œ ì„¹ì…˜ ì¶”ì¶œ"""
        pattern = rf'<{section}><!\[CDATA\[(.*?)\]\]></{section}>'
        matches = re.findall(pattern, content, re.DOTALL)
        return '\n'.join(matches)

    def _add_issue(self, file_stat: FileStats, issue: QAIssue):
        """ì´ìŠˆ ì¶”ê°€"""
        self.qa_issues.append(issue)
        file_stat.issues.append(issue)

    def _is_uninitialized_critical_var(self, line: str) -> bool:
        """ì¤‘ìš” íƒ€ì…ì˜ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ë³€ìˆ˜"""
        pattern = r'^\s*\w+\s*:\s*(REAL|LREAL|POINTER)\b(?!.*:=)'
        return bool(re.search(pattern, line, re.IGNORECASE))

    def _is_large_array(self, line: str) -> bool:
        """ëŒ€ìš©ëŸ‰ ë°°ì—´"""
        match = re.search(r'ARRAY\s*\[\s*(\d+)\s*\.\.\s*(\d+)\s*\]', line, re.IGNORECASE)
        if match:
            size = int(match.group(2)) - int(match.group(1)) + 1
            return size > 1000
        return False

    def _check_naming(self, line: str, file_type: str) -> Optional[str]:
        """ëª…ëª… ê·œì¹™ ê²€ì‚¬"""
        match = re.search(r'^\s*(\w+)\s*:\s*(\w+)', line)
        if match:
            var_name = match.group(1)
            var_type = match.group(2).upper()

            # ìƒìˆ˜ëŠ” ì˜ˆì™¸
            if var_name.isupper():
                return None

            # í—ê°€ë¦¬ì•ˆ í‘œê¸°ë²• ê²€ì‚¬
            prefixes = {
                'BOOL': 'b', 'INT': 'n', 'DINT': 'n', 'REAL': 'f', 'LREAL': 'f',
                'STRING': 's', 'WORD': 'w', 'DWORD': 'dw', 'BYTE': 'by',
                'POINTER': 'p', 'ARRAY': 'a', 'TIME': 't', 'TON': 'ton', 'TOF': 'tof'
            }

            expected_prefix = prefixes.get(var_type)
            if expected_prefix and not var_name.lower().startswith(expected_prefix):
                # FB, FC ê°™ì€ ì ‘ë‘ì‚¬ëŠ” í—ˆìš©
                if not re.match(r'^(fb|fc|st|e|i|o|io)[A-Z_]', var_name, re.IGNORECASE):
                    return f"'{var_name}'ì— íƒ€ì… ì ‘ë‘ì‚¬ '{expected_prefix}' ê¶Œì¥"
        return None

    def _check_type_narrowing(self, line: str) -> Optional[str]:
        """íƒ€ì… ì¶•ì†Œ ê²€ì‚¬"""
        patterns = [
            (r'DINT_TO_INT\s*\(', 'DINTâ†’INT'),
            (r'LINT_TO_DINT\s*\(', 'LINTâ†’DINT'),
            (r'LINT_TO_INT\s*\(', 'LINTâ†’INT'),
            (r'LREAL_TO_REAL\s*\(', 'LREALâ†’REAL'),
            (r'REAL_TO_INT\s*\(', 'REALâ†’INT'),
            (r'REAL_TO_DINT\s*\(', 'REALâ†’DINT'),
            (r'LREAL_TO_INT\s*\(', 'LREALâ†’INT'),
            (r'DWORD_TO_WORD\s*\(', 'DWORDâ†’WORD'),
            (r'DWORD_TO_BYTE\s*\(', 'DWORDâ†’BYTE'),
        ]
        for pattern, desc in patterns:
            if re.search(pattern, line, re.IGNORECASE):
                return desc
        return None

    def _check_real_comparison(self, line: str) -> bool:
        """REAL ì§ì ‘ ë¹„êµ"""
        # := í• ë‹¹ì´ ì•„ë‹Œ = ë¹„êµì—ì„œ REAL ë³€ìˆ˜ ì‚¬ìš©
        if ':=' in line:
            return False
        # f, r ì ‘ë‘ì‚¬ ë³€ìˆ˜ì™€ = ë¹„êµ
        pattern = r'\b[fr]\w+\s*=\s*[fr]\w+\b|\b[fr]\w+\s*=\s*\d+\.\d+'
        return bool(re.search(pattern, line, re.IGNORECASE))

    def _check_division_by_zero(self, line: str) -> bool:
        """0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ê°€ëŠ¥ì„±"""
        # ë³€ìˆ˜ë¡œ ë‚˜ëˆ„ëŠ” ê²½ìš°
        if re.search(r'/\s*[a-zA-Z_]\w*\s*[;)]', line):
            # ì§ì „ì— 0 ì²´í¬ê°€ ì—†ìœ¼ë©´ ìœ„í—˜
            return True
        return False

    def _check_magic_number(self, line: str) -> Optional[str]:
        """ë§¤ì§ ë„˜ë²„"""
        # ì£¼ì„ ì œì™¸
        code = re.sub(r'//.*$', '', line)
        code = re.sub(r'\(\*.*?\*\)', '', code)

        # ë°°ì—´ ì¸ë±ìŠ¤, ì‹œê°„ê°’ ì œì™¸
        code = re.sub(r'\[\s*\d+\s*\]', '', code)
        code = re.sub(r'T#\d+\w+', '', code)
        code = re.sub(r'#\d+', '', code)  # 16#FF ë“±

        # 2ìë¦¬ ì´ìƒ ìˆ«ì
        match = re.search(r'(?<![:\w#])\b(\d{3,})\b', code)
        if match:
            return match.group(1)
        return None

    def _check_hardcoded_time(self, line: str) -> bool:
        """í•˜ë“œì½”ë”©ëœ ì‹œê°„"""
        return bool(re.search(r'T#\d+(?:ms|s|m|h)', line, re.IGNORECASE))

    def _is_commented_code(self, line: str) -> bool:
        """ì£¼ì„ ì²˜ë¦¬ëœ ì½”ë“œ"""
        if line.strip().startswith('//'):
            code_part = line.strip()[2:].strip()
            # ST í‚¤ì›Œë“œë‚˜ í• ë‹¹ë¬¸ì´ ìˆìœ¼ë©´ ì½”ë“œë¡œ íŒë‹¨
            if re.search(r':=|;\s*$|\bIF\b|\bFOR\b|\bWHILE\b|\bEND_', code_part, re.IGNORECASE):
                return True
        return False


def generate_markdown_report(report: Dict) -> str:
    """Markdown ë¦¬í¬íŠ¸ ìƒì„±"""
    md = []
    md.append("# TwinCAT í”„ë¡œì íŠ¸ QA ë¶„ì„ ë¦¬í¬íŠ¸")
    md.append("")
    md.append(f"**ë¶„ì„ ì¼ì‹œ**: {report['generated_at']}")
    md.append(f"**í”„ë¡œì íŠ¸ ê²½ë¡œ**: `{report['project_path']}`")
    md.append("")

    # ìš”ì•½
    s = report['summary']
    md.append("## ğŸ“Š í”„ë¡œì íŠ¸ ìš”ì•½")
    md.append("")
    md.append(f"| í•­ëª© | ê°’ |")
    md.append(f"|------|-----|")
    md.append(f"| ì´ íŒŒì¼ ìˆ˜ | {s['total_files']}ê°œ |")
    md.append(f"| POU (í”„ë¡œê·¸ë¨/FB/í•¨ìˆ˜) | {s['total_pou']}ê°œ |")
    md.append(f"| GVL (ì „ì—­ ë³€ìˆ˜) | {s['total_gvl']}ê°œ |")
    md.append(f"| DUT (ë°ì´í„° íƒ€ì…) | {s['total_dut']}ê°œ |")
    md.append(f"| ì´ ì½”ë“œ ë¼ì¸ | {s['total_lines']:,}ì¤„ |")
    md.append(f"| **ì´ QA ì´ìŠˆ** | **{s['total_issues']}ê°œ** |")
    md.append(f"| ğŸ”´ Critical | {s['critical_count']}ê°œ |")
    md.append(f"| ğŸŸ¡ Warning | {s['warning_count']}ê°œ |")
    md.append(f"| ğŸ”µ Info | {s['info_count']}ê°œ |")
    md.append("")

    # ì¹´í…Œê³ ë¦¬ë³„ ì´ìŠˆ
    md.append("## ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ì´ìŠˆ")
    md.append("")
    md.append("| ì¹´í…Œê³ ë¦¬ | ê±´ìˆ˜ | ì„¤ëª… |")
    md.append("|----------|------|------|")
    categories = {
        'Safety': 'ì•ˆì „ - ì ì¬ì  ë²„ê·¸, ëŸ°íƒ€ì„ ì˜¤ë¥˜',
        'Performance': 'ì„±ëŠ¥ - ë©”ëª¨ë¦¬, ì‹¤í–‰ ì†ë„',
        'Maintainability': 'ìœ ì§€ë³´ìˆ˜ - ê°€ë…ì„±, ë³µì¡ë„',
        'Style': 'ìŠ¤íƒ€ì¼ - ëª…ëª… ê·œì¹™, ì½”ë”© í‘œì¤€'
    }
    for cat, desc in categories.items():
        count = s.get('by_category', {}).get(cat, 0)
        md.append(f"| {cat} | {count}ê°œ | {desc} |")
    md.append("")

    # Critical ì´ìŠˆ
    critical_issues = [i for i in report['issues'] if i['severity'] == 'Critical']
    if critical_issues:
        md.append("## ğŸ”´ Critical Issues (ì¦‰ì‹œ ê²€í†  í•„ìš”)")
        md.append("")
        md.append("| íŒŒì¼ | ë¼ì¸ | ê·œì¹™ | ë©”ì‹œì§€ |")
        md.append("|------|------|------|--------|")
        for issue in critical_issues[:50]:
            file_name = Path(issue['file']).name
            md.append(f"| {file_name} | {issue['line']} | {issue['rule_id']} | {issue['message'][:50]} |")
        if len(critical_issues) > 50:
            md.append(f"| ... | | | *ì™¸ {len(critical_issues) - 50}ê°œ* |")
        md.append("")

    # ê·œì¹™ë³„ í†µê³„
    md.append("## ğŸ“‹ ê·œì¹™ë³„ ì´ìŠˆ í†µê³„")
    md.append("")
    md.append("| ê·œì¹™ ID | ì‹¬ê°ë„ | ì¹´í…Œê³ ë¦¬ | ê±´ìˆ˜ |")
    md.append("|---------|--------|----------|------|")
    for rule_id, data in sorted(report['issues_by_rule'].items()):
        severity_icon = {'Critical': 'ğŸ”´', 'Warning': 'ğŸŸ¡', 'Info': 'ğŸ”µ'}.get(data['severity'], '')
        md.append(f"| {rule_id} | {severity_icon} {data['severity']} | {data['category']} | {data['count']}ê°œ |")
    md.append("")

    # ë³µì¡ë„ ë†’ì€ íŒŒì¼
    complex_files = sorted([f for f in report['files'] if f['complexity'] > 10],
                          key=lambda x: x['complexity'], reverse=True)[:10]
    if complex_files:
        md.append("## âš ï¸ ë³µì¡ë„ ë†’ì€ íŒŒì¼ (Top 10)")
        md.append("")
        md.append("| íŒŒì¼ | íƒ€ì… | ë¼ì¸ìˆ˜ | ë³µì¡ë„ | ì´ìŠˆìˆ˜ |")
        md.append("|------|------|--------|--------|--------|")
        for f in complex_files:
            md.append(f"| {f['name']} | {f['pou_type']} | {f['lines']} | {f['complexity']} | {f['issue_count']} |")
        md.append("")

    return '\n'.join(md)


if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì • (ëª…ë ¹ì¤„ ì¸ì ë˜ëŠ” ê¸°ë³¸ê°’)
    if len(sys.argv) > 1:
        PROJECT_PATH = sys.argv[1]
    else:
        PROJECT_PATH = r"D:\00.Comapre\pollux_hcds_ald_mirror_ffff\Src_Diff\PLC\PM1\PM1"

    # ë¶„ì„ ì‹¤í–‰
    analyzer = TwinCATSingleProjectAnalyzer(PROJECT_PATH)
    report = analyzer.analyze()

    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir = Path(r"D:\01. Vscode\Twincat\features\twincat-code-qa-tool\output")
    output_dir.mkdir(exist_ok=True)

    # JSON ì €ì¥
    json_path = output_dir / "single_project_qa_report.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"\nJSON ë¦¬í¬íŠ¸: {json_path}")

    # Markdown ì €ì¥
    md_content = generate_markdown_report(report)
    md_path = output_dir / "single_project_qa_report.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(md_content)
    print(f"Markdown ë¦¬í¬íŠ¸: {md_path}")

    # ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ë¶„ì„ ì™„ë£Œ!")
    print("="*60)
    s = report['summary']
    print(f"ì´ íŒŒì¼: {s['total_files']}ê°œ ({s['total_lines']:,}ì¤„)")
    print(f"ì´ QA ì´ìŠˆ: {s['total_issues']}ê°œ")
    print(f"  ğŸ”´ Critical: {s['critical_count']}ê°œ")
    print(f"  ğŸŸ¡ Warning: {s['warning_count']}ê°œ")
    print(f"  ğŸ”µ Info: {s['info_count']}ê°œ")
